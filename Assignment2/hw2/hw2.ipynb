{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FKZDMi_5iKCA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LightSource\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-A0EQP5iN5L",
    "outputId": "ee2fb2d9-43b0-4650-b07e-05755d75ceac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f00439036bb4960920764ad65a3b68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccd2d420464454eaa4c6597e13624ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f804797e339f45d9a6ed7d8d5f19a384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e19b3057534ab2a46a58cf179137ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# download MNIST training and testing datasets, then prepare corresponding dataloaders (batch size = 100)\n",
    "mnist_train = datasets.MNIST(\"../data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(\"../data\", train=False, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(mnist_train, batch_size = 100, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size = 100, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "PjUrtvq_iUbQ"
   },
   "outputs": [],
   "source": [
    "# initialize the CNN architecture with 4 convolutional layers and 2 MLP layers for standard training\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "model_cnn = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
    "                          nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
    "                          nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "                          nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),\n",
    "                          Flatten(),\n",
    "                          nn.Linear(7*7*64, 100), nn.ReLU(),\n",
    "                          nn.Linear(100, 10)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "M_cv5SjtiWZE"
   },
   "outputs": [],
   "source": [
    "#### Your task: complete the following function\n",
    "def pgd(model, X, y, epsilon=0.1, alpha=0.02, num_iter=10, randomize=False):\n",
    "    \"\"\" Construct PGD adversarial examples for the example (X,y)\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # delta stores the generated perturbation and updates its value iteratively\n",
    "    delta = torch.zeros_like(X, requires_grad=True).to(device)\n",
    "\n",
    "    # Define the optimizer\n",
    "    #optimizer = optim.SGD([delta], lr=alpha)\n",
    "\n",
    "    for t in range(num_iter):\n",
    "        pred = model(X+delta)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        #optimizer.zero_grad()\n",
    "        #optimizer.step()\n",
    "\n",
    "        #delta.data = torch.clamp(delta.data, -epsilon, epsilon)\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        delta.data = (delta + alpha * delta.grad.detach().sign()).data.clamp(-epsilon, epsilon)\n",
    "        delta.grad.zero_()\n",
    "\n",
    "        #if t % 5 == 0:\n",
    "        #    print(t, -loss.item())  \n",
    "        \n",
    "    model.train()\n",
    "    return delta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "N6yvOm8ciZUL"
   },
   "outputs": [],
   "source": [
    "#### Your task: complete the following functions\n",
    "def epoch(loader, model, opt=None):\n",
    "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    if opt == None:\n",
    "        is_training = False\n",
    "    else:\n",
    "        is_training = True\n",
    "    \n",
    "    model.train() if is_training else model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        \n",
    "        #if is_training:\n",
    "        #    opt.zero_grad()\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        if is_training:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "        #total+=y.size(0)\n",
    "        #total_err += (pred.max(dim=1)[1] != y).sum().item()\n",
    "        #total_loss += loss.item() * X.size(0)\n",
    "\n",
    "            \n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct_predictions += predicted.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "    accuracy = correct_predictions / total_samples\n",
    "    average_loss = total_loss / len(loader) \n",
    "    \n",
    "    return 1 - accuracy, average_loss\n",
    "\n",
    "\n",
    "def epoch_adv(loader, model, attack, opt=None, **kwargs):\n",
    "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    if opt == None:\n",
    "        is_training = False\n",
    "    else:\n",
    "        is_training = True\n",
    "    \n",
    "    model.train() if is_training else model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)        \n",
    "\n",
    "        # Generate adversarial examples using the provided attack method\n",
    "        if attack != my_attack:\n",
    "            adversarial_inputs = attack(model,inputs,labels,**kwargs)\n",
    "\n",
    "            outputs = model(inputs + adversarial_inputs)\n",
    "            \n",
    "        else:\n",
    "            adversarial_inputs = attack(model,inputs,labels)\n",
    "\n",
    "            outputs = model(adversarial_inputs)\n",
    "        \n",
    "        \n",
    "        #if is_training:\n",
    "        #    opt.zero_grad()\n",
    "            \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        if is_training:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct_predictions += predicted.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    average_loss = total_loss / len(loader)\n",
    "\n",
    "    return 1 - accuracy, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HDwITEWRiaxv",
    "outputId": "9025c132-fc70-4df8-f630-42394a9ca2b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:11<00:00, 52.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 72.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.280567\t0.031100\t0.647000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:11<00:00, 53.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 68.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 12.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026100\t0.020300\t0.673300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:10<00:00, 54.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 77.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017383\t0.016000\t0.693500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:10<00:00, 55.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 71.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 12.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013267\t0.013000\t0.680100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:11<00:00, 51.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 71.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009950\t0.013200\t0.761500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# specify the optimizer as SGD\n",
    "opt = optim.SGD(model_cnn.parameters(), lr=1e-1)\n",
    "\n",
    "# standard training\n",
    "for t in range(5):\n",
    "    train_err, train_loss = epoch(train_loader, model_cnn, opt)\n",
    "    test_err, test_loss = epoch(test_loader, model_cnn)\n",
    "    adv_err, adv_loss = epoch_adv(test_loader, model_cnn, pgd)\n",
    "\n",
    "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")\n",
    "\n",
    "# save the standard trained model for further evaluation\n",
    "torch.save(model_cnn.state_dict(), \"model_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "4Dht-vSxlloO"
   },
   "outputs": [],
   "source": [
    "# use the same CNN architecture for robust training\n",
    "model_cnn_robust = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
    "                                 nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
    "                                 nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "                                 nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),\n",
    "                                 Flatten(),\n",
    "                                 nn.Linear(7*7*64, 100), nn.ReLU(),\n",
    "                                 nn.Linear(100, 10)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3KKsmaBalooX",
    "outputId": "504c3da5-dcf7-455d-9808-bc21e3b8bc91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:48<00:00, 12.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 76.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501350\t0.035200\t0.109300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:48<00:00, 12.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 77.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.075717\t0.021200\t0.061600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:48<00:00, 12.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 76.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046100\t0.015100\t0.042100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:48<00:00, 12.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 77.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033550\t0.012100\t0.033100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:48<00:00, 12.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 77.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026950\t0.010800\t0.027600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# specify the optimizer as SGD\n",
    "opt = optim.SGD(model_cnn_robust.parameters(), lr=1e-1)\n",
    "\n",
    "# PGD-based adversarial training\n",
    "for t in range(5):\n",
    "    train_err, train_loss = epoch_adv(train_loader, model_cnn_robust, pgd, opt)\n",
    "    test_err, test_loss = epoch(test_loader, model_cnn_robust)\n",
    "    adv_err, adv_loss = epoch_adv(test_loader, model_cnn_robust, pgd)\n",
    "\n",
    "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")\n",
    "\n",
    "# save the standard trained model for further evaluation\n",
    "torch.save(model_cnn_robust.state_dict(), \"model_cnn_robust.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "fT5MZujiN9Da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the standard trained and adversarially trained models\n",
    "model_cnn.load_state_dict(torch.load(\"model_cnn.pt\"))\n",
    "model_cnn_robust.load_state_dict(torch.load(\"model_cnn_robust.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "f48ELj_UN-uI"
   },
   "outputs": [],
   "source": [
    "def fgsm(model, X, y, epsilon=0.1):\n",
    "    \"\"\" Construct FGSM adversarial examples for the example (X,y)\"\"\"\n",
    "    delta = torch.zeros_like(X, requires_grad=True)\n",
    "    loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
    "    loss.backward()\n",
    "    return epsilon * delta.grad.detach().sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "ecDX3ziXPibw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 57.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 72.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: 0.0132 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 47.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 49.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM:  0.5270 0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD (10 iter): 0.7615 0.0276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# clean performance (no attack)\n",
    "print(\"clean:\", \"{:.4f}\".format(epoch(test_loader, model_cnn)[0]),\n",
    "      \"{:.4f}\".format(epoch(test_loader, model_cnn_robust)[0]))\n",
    "\n",
    "# evaluate both models using FGSM attack\n",
    "print(\"FGSM: \", \"{:.4f}\".format(epoch_adv(test_loader, model_cnn, fgsm)[0]),\n",
    "      \"{:.4f}\".format(epoch_adv(test_loader, model_cnn_robust, fgsm)[0]))\n",
    "\n",
    "# evaluate both models using PGD attack\n",
    "print(\"PGD (10 iter):\", \"{:.4f}\".format(epoch_adv(test_loader, model_cnn, pgd, num_iter=10)[0]),\n",
    "      \"{:.4f}\".format(epoch_adv(test_loader, model_cnn_robust, pgd, num_iter=10)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your task: complete the following function\n",
    "def my_attack(model, X, y, epsilon=0.1, alpha=0.02, num_iter=10, randomize=False):\n",
    "    \"\"\" Construct PGD adversarial examples for the example (X,y)\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # delta stores the generated perturbation and updates its value iteratively\n",
    "    delta = torch.zeros_like(X, requires_grad=True).to(device)\n",
    "\n",
    "    # Define the optimizer\n",
    "    #optimizer = optim.SGD([delta], lr=alpha)\n",
    "\n",
    "    for t in range(num_iter):\n",
    "        pred = model(X+delta)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        #optimizer.zero_grad()\n",
    "        #optimizer.step()\n",
    "\n",
    "        #delta.data = torch.clamp(delta.data, -epsilon, epsilon)\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        delta.data = (delta + alpha * delta.grad.detach().sign()).data.clamp(-epsilon, epsilon)\n",
    "        delta.grad.zero_()\n",
    "\n",
    "        #if t % 5 == 0:\n",
    "        #    print(t, -loss.item())  \n",
    "        \n",
    "    model.train()\n",
    "    return delta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def my_attack(model, X, y, epsilon=0.1, alpha=0.01, num_iters=50, random_factor=0.02):\n",
    "    \n",
    "    model.eval()\n",
    "    X_adv = X.clone().detach().requires_grad_(True)\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        outputs = model(X_adv)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, y)\n",
    "\n",
    "        grad = torch.autograd.grad(loss, X_adv)[0]\n",
    "        \n",
    "        # Introduce random noise to the gradient\n",
    "        random_perturbation = torch.randn_like(grad) * random_factor\n",
    "\n",
    "        perturbation = alpha * torch.sign(grad) + random_perturbation\n",
    "\n",
    "        # Clip perturbation to epsilon\n",
    "        X_adv.data = torch.clamp(X_adv + perturbation, min=X - epsilon, max=X + epsilon)\n",
    "        X_adv.data = torch.clamp(X_adv, 0.0, 1.0)\n",
    "\n",
    "    return X_adv.detach()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Adversarial Attack: Iteratively perturbs the input with random noise using a variant of BIM.\n",
    "\n",
    "This function introduces random noise (random_perturbation) to the gradient at each iteration, which can make the attack more versatile and potentially find adversarial examples that are not easily countered by simple defenses.\n",
    "\n",
    "Below you can see the performance of My Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:32<00:00,  3.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:32<00:00,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Attack:  0.3331 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"My Attack: \", \"{:.4f}\".format(epoch_adv(test_loader, model_cnn, my_attack)[0]), \n",
    "      \"{:.4f}\".format(epoch_adv(test_loader, model_cnn_robust, my_attack)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
